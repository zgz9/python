540622523
1.hadoop配置与管理
2.hadoop和操作系统以及关系型数据库之间传递数据
3.独立制定数据集成方案
4.向hadoop提交作业以及查询作业运行情况
5.了解Map-Reduce原理，能书写Map-Reduce程序
6.了解HDFS原理，能熟练地对HDFS中的文件进行管理
7.独立完成pig的安装并且利用pig做简单的数据分析工作
8.能独立完成Hbase的安装和配置
9.了解Hbase的原理并能进行简单的shell操作
10.能独立完成Hive的安装和配置
11.了解Hive的原理及进行HiveQL操作

ESXI

配置文件
hdfs数据写在了哪里 hdfs-site.xml
/data/current/blk***和blk_**.meta元数据
HDFS设计基础与目标
硬件错误是常态。因此需要冗余
流式数据访问。即数据批量读取而非随机读写，Hadoop擅长做的是数据分析而不是事务处理。（oltp随机读随机写）
大规模数据集
简单一致性。为了降低系统复杂性，对文件采用一次性写多次读的逻辑设计，即是文件一经写入，关闭，就不再修改。
程序采用“数据就近”原则分配节点执行

HDFS体系结构
namenode\datanode\事务日志\映像文件\secondarynamenode
namenode
管理文件系统的命名空间
记录每个文件数据块在各个datanode上的位置和副本信息
协调客户端对文件的访问
记录命名空间内的改动或空间本身属性的改动
namenode使用事务日志记录hdfs元数据的变化。使用映像文件fsimage存储文件系统的命名空间，包括文件映射，文件属性等

datanode
负责所在物理节点的存储管理
一次写入，多次读取（不用考虑典型数据库的数据一致性问题，不用加事务锁机制）
文件由数据块组成，典型的块大小是64MB
数据块尽量散布到各个节点

读取数据流程，写入数据流程
HDFS的可靠性
冗余副本策略，机架策略，心跳机制，安全模式，校验和，回收站，元数据保护，快照机制
hdfs-site.xml中设置复制因子指定副本数量，所有数据块都有副本
datanode启动时，遍历本地文件系统，产生一份hdfs数据块和本地文件的对应关系列表blockreport汇报给namenode

集群一般放在不同机架上，机架间带宽要比机架内带宽要小，HDFS的“机架感知”
一般在本机架存放一个副本，在其它机架再存放别的副本，这样可以防止机架失效时丢失数据，也可以提高带宽利用率

namenode周期性从datanode接收心跳信号和块报告
namenode根据块报告验证元数据
没有按时发送心跳的datanode会被标记为宕机，不会再给它任何I/O请求
如果datanode失效造成副本数量下降，并且低于预先设置的阈值（可设置），namenode会检测出这些数据块，并在合适的时机进行重新复制
引发重新复制的原因还包括数据副本本身损坏、磁盘错误，复制因子被增大等

namenode启动时会先经过一个“安全模式”阶段
安全模式阶段不会产生数据写
在此阶段namenode收集各个datanode的报告，当数据块达到最小副本数以上时，会被认为是“安全”的
在一定比例（可设置）的数据块被确定为“安全”后，再过若干时间，安全模式结束
当检测到副本数不足的数据块是，该块会被复制直到达到最小副本数

在文件创立是，每个数据块都产生校验和
校验和会作为单独一个隐藏文件保存在命名空间下
客户端获取数据时可以检查校验和是否相同，从而发现数据块是否损坏
如果正在读取的数据块损坏，则可以继续读取其它副本

删除文件时，其实是放入回收站/trash
回收站里的文件可以快速恢复
可以设置一个时间阈值，当回收站里文件的存放时间超过这个阈值，就被彻底删除，并且释放占用的数据块

元数据保护
映像文件刚和事务日志是namenode的核心数据。可以配置为拥有多个副本
副本会降低namenode的处理速度，但增加安全性
namenode依然是单点，如果发生故障要手工切换

快照
支持存储某个时间点的映像，需要时可以使数据重返这个时间点的状态
hadoop目前还不支持快照，已经列入开发计划

HDFS文件的操作方式包括命令行方式和API方式
hadoop dfsadmin -report查看HDFS基本统计信息
hadoop dfsadmin -safemode enter进入安全模式
hadoop dfsadmin -safemode leave退出安全模式

添加节点（用脚本批量修改配置文件）
新节点安装好hadoop，把namenode的有关配置文件复制到该节点，修改master和slaves文件，增加该节点
设置ssh免密码进出该节点，单独启动该节点上的datanode和tasktracker，运行start-balancer.sh进行数据负载均衡

hadoop数据分析平台
Map-reduce的思想就是“分而治之”
mapper负责“分”，即把复杂的任务分解为若干个“简单的任务”执行
简单的任务几个含义1.数据规模大大缩小2.就近计算，数据所在节点计算3.小任务可以并行计算，彼此间几乎没有依赖关系
reducer对map阶段的结果进行汇总
reducer的数目由mapred-site.xml配置文件里的项目mapred.reduce.tasks决定。缺省值为1，用户可以覆盖之
shuffler在mapper和reducer中间的一个步骤

性能调优
究竟需要多少个reducer
输入：大文件优于小文件
减少网络传输：压缩map的输出
优化每个节点能运行的任务数：mapred.tasktracker.map.tasks.maximum和mapred.tasktracker.reduce.tasks.maximum（缺省值均为2）

调度机制
缺省为先入先出作业队列调度，支持公平调度器，支持容量调度器
任务执行优化
推测式执行，缺省打开。重用JVM。忽略模式。

错误处理机制：硬件故障是指jobtracker故障或tasktracker故障
map任务失败，重新执行
reducer任务失败，继续执行。
任务失败 最大任务失败数如何设置。。

审计日志
log4j.properties配置为INFO

第三方工具
Ganglia,Chukwa,Openstack

hadoop aip开发步骤
确定目标，开发软件，测试结果
使用eclipse等软件

数据筛选程序
路由器日志，需要提取MAC地址和时间，删去其他内容
思路，源文件--》Mapper（分割原始数据，输出所需数据，处理异常数据）--》输出到hdfs上

context.write(NullWritable.get(),out); //输出  key \t value 如果key或value为空就不会输出\t
context.getCounter(Counter.LINESKIP).increment(1);//计数器递增

倒排索引
电话清单
源文件--》Mapper（分割原始数据，以被叫作为key，以主叫作为value）
--》Reducer（拥有相同被叫的主叫号码们，把主叫号码汇总，输出倒序索引）
--》输出到HDFS

Pig 
hadoop客户端
使用类似于SQL的面向数据流的语言PigLatin
Pig Latin可以完成排序，过滤，求和，聚组，关联等操作，可以支持自定义函数
Pig自动把Pig Latin映射为Map-Reduce作业上传到集群运行，减少用户编写Java程序的苦恼
三种运行方式:Grunt shell,脚本方式，嵌入式

Hbase
Google Bigtable的开源实现
列式数据库
可集群化
可以使用shell、web、api等多种方式访问
适合高读写（insert）的场景
HQL查询语言
NoSQL的典型代表产品

Hive
数据仓库工具。可以把Hadoop下的原始结构化数据变成Hive中的表
支持一种与SQL几乎完全相同的语言HiveQL。除了不支持更新、索引和事务，几乎SQL的其它特征都能支持
可以看成是从SQL到Map-Reduce的映射器
提供shell、JDBC/ODBC、Thrift、web等接口

Zookeeper
Google Chubby的开源实现
用于协调分布式系统上的各种服务。例如确认消息是否准确到达，防止单点失效，处理负载均衡等
应用场景：Hbase，实现Namenode自动切换
工作原理：领导者，跟随者以及选举过程
它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等

Sqoop
用于在Hadoop和关系型数据块之间交换数据
通过JDBC接口连入关系型数据库

Avro
数据序列化工具，由Hadoop的创始人Doug Cutting主持开发
用于支持大批量数据交换的应用。支持二进制序列化方式，可以便捷，快速地处理大量数据
动态语言友好，Avro提供的机制使动态语言可以方便地处理Avro数据。
Thrift接口

Chukwa
架构在Hadoop之上的数据采集与分析框架
主要进行日志采集和分析
通过安装在收集节点的“代理”采集最原始的日志数据
代理将数据发给收集器
收集器定时将数据写入Hadoop集群
指定定时启动的Map-Reduce作业对数据进行加工处理和分析
Hadoop基础管理中心（HICC）最终展示数据

Cassandra
NoSQL，分布式的Key-Value型数据库，由Facebook贡献
与Hbase类似，也是借鉴Google Bigtable的思想体系
只有顺序写，没有随机写的设计，满足高负荷情形的性能需求

Hbase简介
一个分布式的、面向列的开源数据库，该技术源于Chang et al所攥写的Google论文“Bigtable”：一个结构化数据的分布式存储系统
明白Hbase的几个概念，行健，列族，时间戳，可扩展性，-ROOT-,.META.，数据区的可扩展。
Hbase安装的时候，要查询一下与Hadoop匹配的版本再安装，否则会出现莫名其妙的错误。
